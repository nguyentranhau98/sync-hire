"""
SyncHire AI Interview Agent
Powered by GetStream Vision-Agents with Gemini Live

This agent:
1. Joins interview calls when invited
2. Asks personalized interview questions
3. Listens to candidate responses
4. Adapts questions based on answers
5. Sends results to Next.js webhook
"""

import os
import asyncio
import httpx
import logging
from typing import List
from datetime import datetime
from contextlib import asynccontextmanager
from dotenv import load_dotenv

# FastAPI imports (for HTTP endpoints)
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# Vision-Agents imports
from vision_agents.core.edge.types import User
from vision_agents.core.agents import Agent
from vision_agents.plugins import getstream, openai, gemini

# Custom processors
from processors.interview_completion_processor import InterviewCompletionProcessor

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # Console output
        logging.FileHandler('agent.log', mode='a')  # File output
    ]
)
logger = logging.getLogger(__name__)

# Enable DEBUG logging for vision_agents to see more details
logging.getLogger("vision_agents").setLevel(logging.INFO)
logging.getLogger("vision_agents.plugins.gemini").setLevel(logging.INFO)
logging.getLogger("vision_agents.plugins.openai").setLevel(logging.INFO)

logger.info("=" * 80)
logger.info("Agent started - logging to agent.log")
logger.info("=" * 80)

# Load environment variables
load_dotenv()


# Lifespan context manager for startup/shutdown
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifespan events"""
    global interview_agent

    # Startup
    logger.info("üöÄ Starting SyncHire AI Interview Agent...")

    # Only initialize if API keys are configured
    stream_key = os.getenv("STREAM_API_KEY")
    gemini_key = os.getenv("GEMINI_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")

    if stream_key and (gemini_key or openai_key):
        try:
            await interview_agent.initialize()
        except Exception as e:
            logger.error(f"Failed to initialize agent: {e}")
            logger.info("Agent will remain uninitialized - check API keys")
    else:
        logger.warning("‚ö†Ô∏è  Skipping agent initialization - missing API keys")
        logger.info("   Set STREAM_API_KEY and (GEMINI_API_KEY or OPENAI_API_KEY)")

    yield

    # Shutdown
    logger.info("üîÑ Server shutting down gracefully...")
    # Note: Background interview tasks will continue running autonomously
    # The Vision-Agents framework handles cleanup internally


# Initialize FastAPI app for HTTP endpoints
app = FastAPI(
    title="SyncHire AI Interview Agent",
    description="Vision-Agents powered AI interviewer",
    version="0.2.0",
    lifespan=lifespan,
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Request/Response models
class Question(BaseModel):
    """Individual interview question"""
    id: str
    text: str
    type: str
    duration: int


class JoinInterviewRequest(BaseModel):
    """Request to join an interview"""
    callId: str
    questions: List[Question]
    candidateName: str
    jobTitle: str


class HealthResponse(BaseModel):
    """Health check response"""
    status: str
    service: str
    version: str
    timestamp: str
    agent_initialized: bool


def get_llm():
    """Get the appropriate LLM based on available API keys.
    Prioritizes Gemini if API key is set, falls back to OpenAI."""
    gemini_key = os.getenv("GEMINI_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")

    if gemini_key:
        logger.info("ü§ñ Using Gemini Live for realtime audio")
        # Use default model (gemini-2.5-flash-native-audio-preview)
        # which is specifically optimized for native audio
        # Disable affective dialog (emotion awareness) as it's not supported
        config = {
            "enable_affective_dialog": False,
        }
        return gemini.Realtime(config=config)
    elif openai_key:
        logger.info("ü§ñ Using OpenAI Realtime for audio")
        return openai.Realtime()
    else:
        raise ValueError("No API keys configured. Set GEMINI_API_KEY or OPENAI_API_KEY")


class InterviewAgent:
    """AI Interviewer Agent using Vision-Agents framework"""

    def __init__(self):
        self.agent = None
        self.current_interview = None
        self.nextjs_webhook_url = os.getenv("NEXTJS_WEBHOOK_URL", "http://localhost:3000")
        self.is_initialized = False

    async def initialize(self):
        """Initialize the AI agent"""
        if self.is_initialized:
            logger.warning("Agent already initialized")
            return

        logger.info("ü§ñ Initializing SyncHire AI Interviewer Agent...")

        try:
            # Load instructions
            instructions = self._load_instructions()

            # Create agent with Gemini (preferred) or OpenAI fallback
            self.agent = Agent(
                edge=getstream.Edge(),
                agent_user=User(
                    name="AI Interviewer"
                ),
                instructions=instructions,
                llm=get_llm(),
                processors=[]
            )

            # Register agent user with Stream
            await self.agent.create_user()
            logger.info("‚úÖ Agent initialized successfully")
            self.is_initialized = True

        except Exception as e:
            logger.error(f"‚ùå Error initializing agent: {e}", exc_info=True)
            raise

    def _load_instructions(self) -> str:
        """Load agent instructions from Markdown file"""
        instructions_path = "interview_instructions.md"

        try:
            with open(instructions_path, "r") as f:
                instructions = f.read()
            logger.info(f"üìÑ Loaded instructions from {instructions_path}")
            return instructions
        except FileNotFoundError:
            logger.warning(f"‚ö†Ô∏è  {instructions_path} not found, using default")
            return self._default_instructions()

    def _default_instructions(self) -> str:
        """Fallback instructions if file not found"""
        return """
You are a professional AI interviewer for SyncHire.

Your role:
1. Greet the candidate warmly and professionally
2. Ask interview questions one at a time
3. Listen carefully to their responses
4. Ask 1-2 follow-up questions for clarification
5. Be supportive and encouraging
6. Maintain a conversational, natural tone
7. After 8-10 questions, thank the candidate and end the interview

Guidelines:
- Speak clearly and at a moderate pace
- Allow 2-3 minutes per question
- Don't interrupt the candidate
- Be patient and understanding
- Keep questions focused and specific
"""

    async def join_interview(
        self,
        call_id: str,
        questions: List[str],
        candidate_name: str,
        job_title: str
    ):
        """
        Join a specific interview call
        Creates a NEW agent instance for this interview to avoid conflicts

        Args:
            call_id: Stream call ID to join
            questions: List of interview questions to ask
            candidate_name: Candidate's name for personalization
            job_title: Job position being interviewed for
        """
        logger.info(f"üéØ Joining interview: {call_id}")
        logger.info(f"üìã Questions to ask: {len(questions)}")

        # Update instructions with personalized context
        logger.info("üìù Personalizing instructions...")
        personalized_instructions = self._personalize_instructions(
            questions, candidate_name, job_title
        )

        # Create a NEW agent instance for this interview
        # This allows multiple concurrent interviews without conflicts
        logger.info("ü§ñ Creating new agent instance for this interview...")
        interview_agent = Agent(
            edge=getstream.Edge(),
            agent_user=User(
                name="AI Interviewer"
            ),
            instructions=personalized_instructions,
            llm=get_llm(),
            processors=[]
        )

        # Register agent user with Stream
        await interview_agent.create_user()
        logger.info("‚úÖ New agent instance created")

        # Store current interview context
        self.current_interview = {
            "call_id": call_id,
            "candidate_name": candidate_name,
            "job_title": job_title,
            "questions": questions,
            "started_at": datetime.utcnow().isoformat()
        }

        # Join the existing Stream call (call was already created by Next.js)
        logger.info(f"üìû Getting call reference for: {call_id}")
        call = interview_agent.edge.client.video.call("default", call_id)

        logger.info(f"üîó Attempting to join call...")
        try:
            # Create smart completion processor
            async def end_call_callback():
                """Callback when interview is detected as complete"""
                logger.info(f"‚è∞ Waiting 3 seconds for final audio to play...")
                await asyncio.sleep(3)
                logger.info(f"üìû Ending call: {call_id}")
                try:
                    # Close the agent's connection to leave the call
                    if interview_agent._connection:
                        await interview_agent._connection.close()
                        logger.info(f"‚úÖ Call ended successfully")

                        # Send interview completion webhook
                        await self._send_interview_completion_webhook(
                            call_id=call_id,
                            candidate_name=candidate_name,
                            job_title=job_title,
                            duration_minutes=completion_processor.get_duration_minutes()
                        )
                    else:
                        logger.warning(f"‚ö†Ô∏è No active connection to close")
                except Exception as e:
                    logger.error(f"‚ùå Error leaving call: {e}")

            completion_processor = InterviewCompletionProcessor(
                expected_questions=len(questions),
                minimum_duration_minutes=3,  # Reduced from 8 to 3 minutes
                completion_callback=end_call_callback
            )

            # Add processor to agent
            interview_agent.processors.append(completion_processor)
            await completion_processor.setup(interview_agent)

            # Join call and let agent run autonomously
            # The agent will automatically detect participants and start the interview
            # It will run in the background without blocking
            await interview_agent.join(call)
            logger.info(f"‚úÖ Agent joined call successfully")

            # Send initial prompt to start the interview
            # Without this, the agent waits for the candidate to speak first
            logger.info(f"üé§ Sending initial prompt to start interview")
            await interview_agent.simple_response(
                text=f"Start the interview now by greeting {candidate_name} and asking the first question."
            )

            # Agent is now running autonomously in the background
            # It will conduct the interview based on instructions
            # The Vision-Agents framework handles the conversation automatically
            logger.info(f"üéØ Agent is now conducting interview autonomously")

            # Wait for smart processor to detect completion (with 15 min timeout)
            await completion_processor.wait_for_completion(timeout=900)

        except Exception as e:
            logger.error(f"‚ùå Error during interview: {e}", exc_info=True)
            raise

    def _personalize_instructions(
        self,
        questions: List[str],
        candidate_name: str,
        job_title: str
    ) -> str:
        """Add personalized context to agent instructions"""
        base_instructions = self._load_instructions()

        questions_text = "\n".join([
            f"{i+1}. {q}" for i, q in enumerate(questions)
        ])

        personalized = f"""
{base_instructions}

INTERVIEW CONTEXT:
- Candidate: {candidate_name}
- Position: {job_title}

QUESTIONS TO ASK (in order):
{questions_text}

Start the interview by greeting {candidate_name} and asking the first question.
After each answer, either ask a follow-up or move to the next question.
"""
        return personalized

    async def _send_interview_completion_webhook(
        self,
        call_id: str,
        candidate_name: str,
        job_title: str,
        duration_minutes: float
    ):
        """
        Send interview completion webhook to Next.js
        """
        logger.info("üì§ Sending interview completion notification...")

        payload = {
            "call_id": call_id,
            "candidate_name": candidate_name,
            "job_title": job_title,
            "duration_minutes": round(duration_minutes, 2),
            "completed_at": datetime.utcnow().isoformat(),
            "status": "completed"
        }

        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    f"{self.nextjs_webhook_url}/api/webhooks/interview-complete",
                    json=payload,
                    timeout=30.0
                )
                response.raise_for_status()
                logger.info(f"‚úÖ Interview completion notification sent successfully")
            except Exception as e:
                logger.error(f"‚ùå Failed to send completion webhook: {e}")


# Global agent instance
interview_agent = InterviewAgent()


# FastAPI Endpoints
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    return HealthResponse(
        status="healthy",
        service="sync-hire-vision-agent",
        version="0.2.0",
        timestamp=datetime.utcnow().isoformat(),
        agent_initialized=interview_agent.is_initialized
    )


async def _run_interview_background(
    call_id: str,
    questions: List[Question],
    candidate_name: str,
    job_title: str
):
    """
    Background task to run the interview
    This allows the HTTP endpoint to return immediately
    The agent will join the call and run autonomously without blocking
    """
    try:
        logger.info(f"üéØ Background task: Starting interview for {candidate_name}")

        # Extract question text from Question objects
        question_texts = [q.text for q in questions]

        await interview_agent.join_interview(
            call_id=call_id,
            questions=question_texts,
            candidate_name=candidate_name,
            job_title=job_title
        )
        logger.info(f"‚úÖ Background task: Agent joined and is conducting interview for {call_id}")
    except asyncio.CancelledError:
        logger.info(f"‚ö†Ô∏è  Background task cancelled for {call_id}")
        raise
    except Exception as e:
        logger.error(f"‚ùå Background task: Error in interview {call_id}: {e}", exc_info=True)


@app.post("/join-interview")
async def join_interview(request: JoinInterviewRequest, background_tasks: BackgroundTasks):
    """
    Join an interview call

    This endpoint is called by Next.js to invite the agent to a call.
    The interview runs in a background task so the endpoint returns immediately.
    """
    logger.info(f"üìû Received join-interview request for call: {request.callId}")

    if not interview_agent.is_initialized:
        logger.error("‚ùå Agent not initialized")
        return {
            "success": False,
            "error": "Agent not initialized - check STREAM_API_KEY and (GEMINI_API_KEY or OPENAI_API_KEY)"
        }

    # Add interview to background tasks
    logger.info(f"‚ûï Adding interview to background tasks for {request.candidateName}")
    logger.info(f"   Questions: {len(request.questions)} question(s)")

    background_tasks.add_task(
        _run_interview_background,
        call_id=request.callId,
        questions=request.questions,
        candidate_name=request.candidateName,
        job_title=request.jobTitle
    )

    logger.info(f"‚úÖ Interview task scheduled: {request.callId}")
    return {
        "success": True,
        "message": "Agent will join interview shortly",
        "callId": request.callId
    }


@app.get("/")
async def root():
    """Root endpoint"""
    # Determine which LLM is active
    gemini_key = os.getenv("GEMINI_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")

    if gemini_key:
        llm_name = "Google Gemini 2.0 Flash"
    elif openai_key:
        llm_name = "OpenAI GPT-4o Realtime"
    else:
        llm_name = "None (no API keys configured)"

    return {
        "service": "SyncHire AI Interview Agent",
        "version": "0.2.0",
        "status": "running",
        "framework": "Vision-Agents",
        "llm": llm_name,
        "agent_initialized": interview_agent.is_initialized,
        "endpoints": {
            "health": "/health",
            "join_interview": "/join-interview (POST)",
            "docs": "/docs",
        },
    }


if __name__ == "__main__":
    port = int(os.getenv("PORT", "8080"))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=True,
        log_level="info",
    )
